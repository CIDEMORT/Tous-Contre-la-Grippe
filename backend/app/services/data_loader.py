import pandas as pd
from pathlib import Path
from sqlalchemy import Column, Integer, String, Float, Date, DateTime, Text, Boolean
from sqlalchemy.types import TypeDecorator
from app.config import get_settings
from app.database import SessionLocal, Base, engine
from datetime import datetime
import logging

settings = get_settings()
logger = logging.getLogger(__name__)

# Mapping des types pandas vers SQLAlchemy
PANDAS_TO_SQL_TYPES = {
    'int64': Integer,
    'int32': Integer,
    'float64': Float,
    'float32': Float,
    'object': String(500),  # String par d√©faut
    'bool': Boolean,
    'datetime64[ns]': DateTime,
}

def clean_column_name(col_name: str) -> str:
    """
    Nettoie les noms de colonnes pour SQLite
    - Enl√®ve les espaces
    - Remplace les caract√®res sp√©ciaux
    - Met en lowercase
    """
    col_name = col_name.strip().lower()
    col_name = col_name.replace(' ', '_')
    col_name = col_name.replace('-', '_')
    col_name = col_name.replace('(', '').replace(')', '')
    col_name = col_name.replace('/', '_')
    col_name = col_name.replace('√©', 'e').replace('√®', 'e').replace('√™', 'e')
    col_name = col_name.replace('√†', 'a').replace('√¢', 'a')
    col_name = col_name.replace('√¥', 'o')
    col_name = col_name.replace('√π', 'u').replace('√ª', 'u')
    col_name = col_name.replace('√ß', 'c')
    return col_name

def infer_sql_type(dtype, sample_values):
    """
    Inf√®re le type SQL √† partir du type pandas et des valeurs
    """
    dtype_str = str(dtype)
    
    # D√©tection de dates
    if 'date' in dtype_str.lower():
        return DateTime
    
    # Essayer de d√©tecter les dates dans les strings
    if dtype_str == 'object' and sample_values is not None:
        try:
            pd.to_datetime(sample_values.dropna().head(5))
            return DateTime
        except:
            pass
    
    # Type par d√©faut selon pandas
    return PANDAS_TO_SQL_TYPES.get(dtype_str, String(500))

def create_table_from_csv(csv_path: Path, table_name: str = None):
    """
    Cr√©e une table dynamiquement √† partir d'un CSV
    """
    logger.info(f"üìÑ Analyse du fichier: {csv_path.name}")
    
    # Lire le CSV avec pandas
    try:
        df = pd.read_csv(csv_path, nrows=100)  # Lire seulement 100 lignes pour l'analyse
    except Exception as e:
        logger.error(f"‚ùå Erreur lecture CSV {csv_path.name}: {e}")
        return None
    
    # Nettoyer les noms de colonnes
    df.columns = [clean_column_name(col) for col in df.columns]
    
    # Nom de la table (utilise le nom du fichier si non sp√©cifi√©)
    if table_name is None:
        table_name = clean_column_name(csv_path.stem)
    
    logger.info(f"üìä Table: {table_name}")
    logger.info(f"üìã Colonnes d√©tect√©es: {', '.join(df.columns)}")
    
    # Cr√©er la classe dynamiquement
    attrs = {
        '__tablename__': table_name,
        'id': Column(Integer, primary_key=True, index=True, autoincrement=True),
        'created_at': Column(DateTime, default=datetime.utcnow),
    }
    
    # Ajouter les colonnes d√©tect√©es
    for col in df.columns:
        sql_type = infer_sql_type(df[col].dtype, df[col])
        attrs[col] = Column(sql_type, nullable=True)
    
    # Cr√©er la classe de mod√®le
    table_class = type(table_name.capitalize() + 'Model', (Base,), attrs)
    
    return table_class, df.columns.tolist()

def load_csv_to_table(csv_path: Path, table_class, columns: list):
    """
    Charge les donn√©es d'un CSV dans la table
    """
    logger.info(f"üì• Chargement des donn√©es de {csv_path.name}...")
    
    # Lire tout le CSV
    try:
        df = pd.read_csv(csv_path)
        df.columns = [clean_column_name(col) for col in df.columns]
    except Exception as e:
        logger.error(f"‚ùå Erreur lecture compl√®te du CSV: {e}")
        return 0
    
    # Convertir en dictionnaires
    records = df.to_dict('records')
    
    # Ins√©rer dans la DB
    db = SessionLocal()
    try:
        # Insertion par batch de 1000
        batch_size = 1000
        total_inserted = 0
        
        for i in range(0, len(records), batch_size):
            batch = records[i:i+batch_size]
            db.bulk_insert_mappings(table_class, batch)
            db.commit()
            total_inserted += len(batch)
            logger.info(f"   ‚úÖ {total_inserted}/{len(records)} lignes ins√©r√©es")
        
        logger.info(f"‚úÖ {total_inserted} lignes charg√©es avec succ√®s")
        return total_inserted
        
    except Exception as e:
        db.rollback()
        logger.error(f"‚ùå Erreur lors de l'insertion: {e}")
        return 0
    finally:
        db.close()

def load_all_csv_data():
    """
    Charge tous les fichiers CSV du dossier data/raw
    """
    csv_path = Path(settings.csv_data_path)
    
    if not csv_path.exists():
        logger.warning(f"‚ö†Ô∏è  Dossier CSV non trouv√©: {csv_path}")
        logger.info(f"üí° Cr√©ez le dossier et ajoutez vos fichiers CSV")
        csv_path.mkdir(parents=True, exist_ok=True)
        return
    
    logger.info(f"üìÅ Recherche de CSV dans: {csv_path}")
    csv_files = list(csv_path.glob("*.csv"))
    
    if not csv_files:
        logger.warning("‚ö†Ô∏è  Aucun fichier CSV trouv√©")
        logger.info(f"üí° Ajoutez vos fichiers CSV dans {csv_path}")
        return
    
    logger.info(f"üìä {len(csv_files)} fichiers CSV trouv√©s")
    
    # Liste des tables qui ont d√©j√† un mod√®le d√©fini dans schemas.py
    PREDEFINED_TABLES = [
        "accessibilite_pharmacies",
        "evolution_actes_age",
        "evolution_doses_age",
        "evolution_actes_region",
        "evolution_doses_region",
        "repartition_lieu_vaccination",
        "actes_doses_region",
        "nombre_pharmacies_periode",
        "donnees_meteo"
    ]
    
    total_loaded = 0
    
    for csv_file in csv_files:
        try:
            table_name = clean_column_name(csv_file.stem)
            
            # Si la table a d√©j√† un mod√®le d√©fini, utiliser le chargement direct
            if table_name in PREDEFINED_TABLES:
                logger.info(f"üìÑ Chargement du CSV pr√©d√©fini: {csv_file.name} ‚Üí {table_name}")
                rows_loaded = load_predefined_csv(csv_file, table_name)
                total_loaded += rows_loaded
                logger.info(f"‚úÖ {csv_file.name} ‚Üí {rows_loaded} lignes charg√©es")
            else:
                # Sinon, cr√©er la table dynamiquement (pour les CSV non pr√©vus)
                logger.info(f"üìÑ Analyse du fichier: {csv_file.name}")
                result = create_table_from_csv(csv_file)
                if result is None:
                    continue
                    
                table_class, columns = result
                
                # Cr√©er la table dans la DB
                Base.metadata.create_all(bind=engine, tables=[table_class.__table__])
                
                # Charger les donn√©es
                rows_loaded = load_csv_to_table(csv_file, table_class, columns)
                total_loaded += rows_loaded
                
                logger.info(f"‚úÖ {csv_file.name} ‚Üí Table '{table_class.__tablename__}' cr√©√©e et remplie")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur avec {csv_file.name}: {e}")
            continue
    

    logger.info(f"üéâ Chargement termin√© ! {total_loaded} lignes totales charg√©es")

def load_predefined_csv(csv_path: Path, table_name: str):
    """
    Charge un CSV dans une table qui a d√©j√† un mod√®le SQLAlchemy d√©fini
    """
    from app.models import schemas
    from sqlalchemy import inspect
    
    # Mapping des noms de tables vers les classes de mod√®les
    MODEL_MAPPING = {
        "accessibilite_pharmacies": schemas.AccessibilitePharmacies,
        "evolution_actes_age": schemas.EvolutionActesAge,
        "evolution_doses_age": schemas.EvolutionDosesAge,
        "evolution_actes_region": schemas.EvolutionActesRegion,
        "evolution_doses_region": schemas.EvolutionDosesRegion,
        "repartition_lieu_vaccination": schemas.RepartitionLieuVaccination,
        "actes_doses_region": schemas.ActesDosesRegion,
        "nombre_pharmacies_periode": schemas.NombrePharmaciesPeriode,
        "donnees_meteo": schemas.DonneesMeteo,
    }
    
    model_class = MODEL_MAPPING.get(table_name)
    if not model_class:
        logger.error(f"‚ùå Mod√®le introuvable pour la table: {table_name}")
        return 0
    
    # Lire le CSV SANS modifier les noms de colonnes
    try:
        df = pd.read_csv(csv_path, sep=None, engine='python')
        df.columns = df.columns.str.replace('\ufeff', '', regex=False)
        df.columns = df.columns.str.replace('(', '_', regex=False)
        df.columns = df.columns.str.replace(')', '', regex=False)

    except Exception as e:
        logger.error(f"‚ùå Erreur lecture du CSV: {e}")
        return 0
    
    logger.info(f"üìã Colonnes du CSV: {list(df.columns)}")
    
    # Utiliser l'inspecteur pour avoir les VRAIS noms de colonnes dans la DB
    inspector = inspect(engine)
    db_columns = {}
    for col in inspector.get_columns(table_name):
        db_columns[col['name']] = col
    
    logger.info(f"üìã Colonnes dans la DB: {list(db_columns.keys())}")
    
    # Cr√©er un mapping CSV ‚Üí Attribut Python du mod√®le
    csv_to_python_attr = {}
    for csv_col in df.columns:
        # Trouver l'attribut Python qui correspond √† cette colonne CSV
        for attr_name in dir(model_class):
            if attr_name.startswith('_'):
                continue
            try:
                attr = getattr(model_class, attr_name)
                if hasattr(attr, 'expression'):
                    # C'est une colonne SQLAlchemy
                    col_name = attr.expression.name
                    if col_name == csv_col:
                        csv_to_python_attr[csv_col] = attr_name
                        logger.info(f"  Mapping: CSV '{csv_col}' ‚Üí Python '{attr_name}' ‚Üí DB '{col_name}'")
                        break
            except:
                continue
    
    # Convertir en dictionnaires
    records = df.to_dict('records')
    
    # Ins√©rer dans la DB
    db = SessionLocal()
    try:
        # Vider la table d'abord
        db.query(model_class).delete()
        db.commit()
        
        # Insertion par batch
        batch_size = 1000
        total_inserted = 0
        
        for i in range(0, len(records), batch_size):
            batch = records[i:i+batch_size]
            
            objects_to_insert = []
            for record in batch:
                obj = model_class()
                
                # Utiliser le mapping qu'on a cr√©√©
                for csv_col, value in record.items():
                    if csv_col in csv_to_python_attr:
                        python_attr = csv_to_python_attr[csv_col]
                        setattr(obj, python_attr, value)
                    elif csv_col in db_columns:
                        # Essai direct si la colonne existe dans la DB
                        setattr(obj, csv_col, value)
                
                objects_to_insert.append(obj)
            
            db.add_all(objects_to_insert)
            db.commit()
            total_inserted += len(objects_to_insert)
            logger.info(f"   ‚úÖ {total_inserted}/{len(records)} lignes ins√©r√©es")
        
        logger.info(f"‚úÖ {total_inserted} lignes charg√©es avec succ√®s dans {table_name}")
        return total_inserted
        
    except Exception as e:
        db.rollback()
        logger.error(f"‚ùå Erreur lors de l'insertion dans {table_name}: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return 0
    finally:
        db.close()